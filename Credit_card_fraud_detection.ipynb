{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Credit_card_fraud_detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsubho/Capstone-Project/blob/master/Credit_card_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzMqwAp0zFyg",
        "colab_type": "text"
      },
      "source": [
        "## Credit Card Fraud Detection\n",
        "\n",
        "In this project you will predict fraudulent credit card transactions with the help of Machine learning models. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "s1QMvZA7zFyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10ba4549-460f-40b5-fe81-98af89dec14d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIyNv3gMzFym",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMJUFeyqzFyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6a285201-5f7e-4a3d-d31e-73468aa1d667"
      },
      "source": [
        "# df = pd.read_csv('creditcard.csv')\n",
        "df = pd.read_csv('https://media.githubusercontent.com/media/rsubho/Capstone-Project/master/creditcard.csv')\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtWijIZIzFyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#observe the different feature type present in the data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfa8M-1bzFys",
        "colab_type": "text"
      },
      "source": [
        "Here we will observe the distribution of our classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "levz_eaWzFyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=df['Class'].value_counts()\n",
        "normal_share=classes[0]/df['Class'].count()*100\n",
        "fraud_share=classes[1]/df['Class'].count()*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FsjPHhazFyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAovsOuOzFy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a scatter plot to observe the distribution of classes with time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZTqD6PGzFy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a scatter plot to observe the distribution of classes with Amount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t5qFaKszFy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop unnecessary columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo02znPPzFy9",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the data into train & test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlkSZm3fzFy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y= #class variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuecHQn6zFy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "X_train, X_test, y_train, y_test = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K5z9OlvzFzB",
        "colab_type": "text"
      },
      "source": [
        "##### Preserve X_test & y_test to evaluate on the test data once you build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAeDulutzFzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.sum(y))\n",
        "print(np.sum(y_train))\n",
        "print(np.sum(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQVJanHVzFzG",
        "colab_type": "text"
      },
      "source": [
        "### Plotting the distribution of a variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1nZ1fgTzFzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the histogram of a variable from the dataset to see the skewness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j17jVaDOzFzK",
        "colab_type": "text"
      },
      "source": [
        "### If there is skewness present in the distribution use:\n",
        "- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOvswGUyzFzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY7JGPqczFzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the histogram of a variable from the dataset again to see the result "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbKlFKiJzFzP",
        "colab_type": "text"
      },
      "source": [
        "## Model Building\n",
        "- Build different models on the imbalanced dataset and see the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "srhzTo9izFzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "from sklearn import linear_model #import the package\n",
        "\n",
        "num_C = ______  #--> list of values\n",
        "cv_num =   #--> list of values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvI5npubzFzT",
        "colab_type": "text"
      },
      "source": [
        "#### perfom cross validation on the X_train & y_train to create:\n",
        "- X_train_cv\n",
        "- X_test_cv \n",
        "- y_train_cv\n",
        "- y_test_cv "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_qCXQ7IzFzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform cross validation\n",
        "\n",
        "#perform hyperparameter tuning\n",
        "\n",
        "#print the evaluation result by choosing a evaluation metric\n",
        "\n",
        "#print the optimum value of hyperparameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-PsNNBTzFzZ",
        "colab_type": "text"
      },
      "source": [
        "### Similarly explore other algorithms by building models like:\n",
        "- KNN\n",
        "- SVM\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC9zU5-xzFza",
        "colab_type": "text"
      },
      "source": [
        "#### Proceed with the model which shows the best result \n",
        "- Apply the best hyperparameter on the model\n",
        "- Predict on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEgb9vMYzFzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = ___  #initialise the model with optimum hyperparameters\n",
        "clf.fit(X_train, y_train)\n",
        "print --> #print the evaluation score on the X_test by choosing the best evaluation metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ASpthdzFzd",
        "colab_type": "text"
      },
      "source": [
        "### Print the important features of the best model to understand the dataset\n",
        "- This will not give much explanation on the already transformed dataset\n",
        "- But it will help us in understanding if the dataset is not PCA transformed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZG3CffgzFzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_imp = []\n",
        "for i in clf.feature_importances_:\n",
        "    var_imp.append(i)\n",
        "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
        "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
        "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
        "\n",
        "# Variable on Index-16 and Index-13 seems to be the top 2 variables\n",
        "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
        "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
        "\n",
        "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
        "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
        "\n",
        "np.random.shuffle(X_train_0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [20, 20]\n",
        "\n",
        "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
        "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
        "            label='Actual Class-0 Examples')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJXLzbAMzFzg",
        "colab_type": "text"
      },
      "source": [
        "## Model building with balancing Classes\n",
        "\n",
        "##### Perform class balancing with :\n",
        "- Random Oversampling\n",
        "- SMOTE\n",
        "- ADASYN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gJixCbYzFzg",
        "colab_type": "text"
      },
      "source": [
        "## Model Building\n",
        "- Build different models on the balanced dataset and see the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdcA5OEUzFzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "from sklearn import linear_model #import the package\n",
        "\n",
        "num_C = ______  #--> list of values\n",
        "cv_num =   #--> list of values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SGybdT9zFzj",
        "colab_type": "text"
      },
      "source": [
        "#### perfom cross validation on the X_train & y_train to create:\n",
        "- X_train_cv\n",
        "- X_test_cv \n",
        "- y_train_cv\n",
        "- y_test_cv "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQcuUB_NzFzk",
        "colab_type": "text"
      },
      "source": [
        "### Random Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kcYnYg27zFzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn import over_sampling #- import the packages\n",
        "\n",
        "#perform cross validation & then balance classes on X_train_cv & y_train_cv using Random Oversampling\n",
        "\n",
        "#perform hyperparameter tuning\n",
        "\n",
        "#print the evaluation result by choosing a evaluation metric\n",
        "\n",
        "#print the optimum value of hyperparameters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4mqCcKwzFzo",
        "colab_type": "text"
      },
      "source": [
        "### Similarly explore other algorithms on balanced dataset by building models like:\n",
        "- KNN\n",
        "- SVM\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VibDNu73zFzp",
        "colab_type": "text"
      },
      "source": [
        "### Print the class distribution after applying SMOTE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8diGGH5HzFzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "sm = over_sampling.SMOTE(random_state=0)\n",
        "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
        "# Artificial minority samples and corresponding minority labels from SMOTE are appended\n",
        "# below X_train and y_train respectively\n",
        "# So to exclusively get the artificial minority samples from SMOTE, we do\n",
        "X_train_smote_1 = X_train_smote[X_train.shape[0]:]\n",
        "\n",
        "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
        "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [20, 20]\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
        "plt.scatter(X_train_smote_1[:X_train_1.shape[0], 0], X_train_smote_1[:X_train_1.shape[0], 1],\n",
        "            label='Artificial SMOTE Class-1 Examples')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
        "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgbd2VJIzFzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform cross validation & then balance classes on X_train_cv & y_train_cv using SMOTE\n",
        "\n",
        "#perform hyperparameter tuning\n",
        "\n",
        "#print the evaluation result by choosing a evaluation metric\n",
        "\n",
        "#print the optimum value of hyperparameters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpQ1ipMgzFzv",
        "colab_type": "text"
      },
      "source": [
        "##### Build models on other algorithms to see the better performing on SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VxKw30KzFzw",
        "colab_type": "text"
      },
      "source": [
        "### Print the class distribution after applying ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOpDpHnyzFzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from imblearn import over_sampling\n",
        "\n",
        "ada = over_sampling.ADASYN(random_state=0)\n",
        "X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train, y_train)\n",
        "# Artificial minority samples and corresponding minority labels from ADASYN are appended\n",
        "# below X_train and y_train respectively\n",
        "# So to exclusively get the artificial minority samples from ADASYN, we do\n",
        "X_train_adasyn_1 = X_train_adasyn[X_train.shape[0]:]\n",
        "\n",
        "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
        "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [20, 20]\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
        "plt.scatter(X_train_adasyn_1[:X_train_1.shape[0], 0], X_train_adasyn_1[:X_train_1.shape[0], 1],\n",
        "            label='Artificial ADASYN Class-1 Examples')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
        "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaSsbCLqzFzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform cross validation & then balance classes on X_train_cv & y_train_cv using ADASYN\n",
        "\n",
        "#perform hyperparameter tuning\n",
        "\n",
        "#print the evaluation result by choosing a evaluation metric\n",
        "\n",
        "#print the optimum value of hyperparameters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S51prTb7zFz1",
        "colab_type": "text"
      },
      "source": [
        "##### Build models on other algorithms to see the better performing on ADASYN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqtRmuvtzFz3",
        "colab_type": "text"
      },
      "source": [
        "### Select the oversampling method which shows the best result on a model\n",
        "- Apply the best hyperparameter on the model\n",
        "- Predict on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1G9UxWJzFz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# perform the best oversampling method on X_train & y_train\n",
        "\n",
        "clf = ___  #initialise the model with optimum hyperparameters\n",
        "clf.fit( ) # fit on the balanced dataset\n",
        "print() --> #print the evaluation score on the X_test by choosing the best evaluation metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIuEOa1yzFz5",
        "colab_type": "text"
      },
      "source": [
        "### Print the important features of the best model to understand the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5knYxX0zFz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_imp = []\n",
        "for i in clf.feature_importances_:\n",
        "    var_imp.append(i)\n",
        "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
        "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
        "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
        "\n",
        "# Variable on Index-13 and Index-9 seems to be the top 2 variables\n",
        "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
        "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
        "\n",
        "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
        "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
        "\n",
        "np.random.shuffle(X_train_0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [20, 20]\n",
        "\n",
        "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
        "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
        "            label='Actual Class-0 Examples')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eHxOMYxzFz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Print the FPR,TPR & select the best threshold from the roc curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7lXxYudzFz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train auc =', metrics.roc_auc_score(_________)\n",
        "fpr, tpr, thresholds = metrics.roc_curve(_________)\n",
        "threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "print(threshold)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}